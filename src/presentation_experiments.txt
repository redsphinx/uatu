experiments for the presentation

(1) Transfer of CNN weights to SCNN
	running_experiments_1, experiment_log_1
	28:training SCN with CNN weights: 2D filters 32, BN_lr_0-0001. use CL 0.00001-0.0001
	vs.
	31.SCNN: random weight initialization
	
(2) Usage of CLR
	running_experiments_1, experiment_log_1
	33.SCNN: RIW, BN, no CL, lr=0.00001
	34.SCNN: RIW, BN, no CL, lr=0.0001
	vs.
	38.SCNN: RIW, BN, CL, lr=0.00001-0.0001
	
(3) Different types of neural distance
	running_experiments_1, experiment_log_1, from line 2607
	57. baseline (concatenate)
	58. neural distance: add
	59. neural distance: multiply

(4) Using ELU instead of ReLU
	running_experiments_1, experiment_log_1
	78. combo: elu + CLR min=0.00005, max=0.0005
	vs.
	57. baseline

(5) Different types of neural distance
	running_experiments_1, experiment_log_1
	92. baseline: debugged network
	vs.
	102. neural_distance=absolute
	vs
	103. neural_distance=subtract
	vs
	104. neural_distance=divide
	
(6) Reducing number of filters
	running_experiments_1, experiment_log_1
	105. adjustable.numfil = 1 + neural_distance=absolute
	
(7) Training in order on all data
	running_experiments_1, experiment_log_1
	109. saving network with config. 105 each 100 epochs. preparation for priming experiments
	
(8) Priming at different epochs
 	running_experiments_1, experiment_log_1
 	111 - 130
 	
(9) Train on 1 dataset only
 	running_experiments_1, experiment_log_1
 	161 - 166
 
(10)Transfer on data with rank 20
 	running_experiments_1, experiment_log_1
 	lines 5881 - 5931
 	
(11)Network trained on ALL the data, test on each test set individually, rank 20
 	running_experiments_1, experiment_log_1
 	after training on all data in order test on all ranking test sets
 	lines 5955 - 5982
 	
(12)Transfer + priming
	running_experiments_1, experiment_log_1
	lines 5985 - 6095

----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------

(13)Transfer learning
	running_experiments_2, log_0.txt
	001 - 034

----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------

(14)Training on mixed data, rank 100
	running_experiments_2, experiment_log_2
	improved baseline SCNN setup 105, minus caviar: rank=100
	
(15)SOTAs
	running_experiments_2, experiment_log_2
	train on viper only: rank=632
	train on prid450 only: rank=225
	train on caviar only: rank=36
	train on grid only: rank=125
	
(16)new SOTAs
	running_experiments_2, log_0.txt
	038 - 042

(17)Problems with euclidean, cosine
	running_experiments_1, experiment_log_1


http://watchingthewatchers.weebly.com/the-netherlands.html#.WUlHxnYrLmE	
	

Text

Hello everyone, my name is Gabi and I will be telling a little something about how deep learning is used in surveillance systems.

Big brother may or may not be watching.

I say that it is.

Fun facts about surveillance in the Netherlands

According to the Dutch website Sargasso, there are at least 200000 surveillance cameras watching over the inhabitants of the Netherlands. Since privately owened cameras are not mandatory to be reported, it it very likely that this number is a lot higher. According to other sources this number may be as high as 1 million cameras. This includes cameras in supermarkets, schools or business areas. 

These cameras are being used for many types of surveillance, for example traffic surveillance, tracking people of interest and also some very specific things such as detecting if luggage is being left unattended in a public space.

However, big brother is not always watching. As the number of cameras used for surveillence is constantly increasing, this becomes a burden for people who need to keep an eye on all these camera feeds. Cameras are getting very cheap and are easy to install in virtually any imaginable space. It should come as no suprise that the demand for the automization of surveillance is also increasing. 

This is where Artificial Intelligence comes in. It may seem that AI is a magic box that can do everything, but actually it is quite difficult to make things work robustly. For example in surveillance systems, there is no AI (yet) that can do many tasks. Currently we create AI that is able to deal with 1 clearly defined task at a time. Various examples of these tasks are:
- person tracking
- person identification
- vehicle tracking
- object detection

In this talk I will be talking about 1 specific problem that we will automate:
- person re-identification

Person identification is when we say "oh look that is Bob, hi Bob!". This is where the AI has learned the identity of Bob and stores representations of the identity of Bob in a database. This is easy to do in closed environments where everybody's identity is known.

But imagine that we have 100 random strange people on the camera at any given moment, such as a crowd in a public space, where it is simply unfeasible to store everybody's ID in a giant database. Also imagine that we have a couple of cameras observing this space from various angles. Then imagine that there is a human security guard being observing these cameras, and he or she sees a person doing something weird, like punch another person and then run away. This security has seen the person who commited the assault and then has to keep an eye on all the cameras to see where this person might be. Since the identity of the person is not known beforehand but has only just been observed, we only have a couple of reference frames of this person. And then the task is to find this person again on the other cameras. This is known as person re-identification.

In literature we say that, 

given the probe, we have to find its match in the gallery of candidates.

In our case we want to create an automated surveillance system that can do person re-identification in an area where there are no more than 100 people on the camera at the same time. The target scenario is where we have a non-cluttered background with optimally just 1 person at a time on the video under more or less the same angle.

Classically we have computer vision algorithms that deal with this. But recently it has been shown that deep learning is capable of outperforming classic computer vision methods when it comes to things like detecting objects, mainly because we don't have to specify hand-crafted features anymore. Deep learning is capable of detecting dicriminating features by itself. 

Which is why we will be using deep learning to solve this problem.

While the main objective is to create a deep learning model that can perform person re-id in the specific scenario, we will also aim to solve some problems that are relevant in person re-id literature. Answering these questions will also lead to a better model that can be used in practice.

Research questions

We deal with 3 research questions:

(1) Can we avoid the use of an explicit Mahalanobis distance metric?
(2) How can we optimally make use of all datasets available to us?
(3) How can we make use of the fact that we will have some minor knowledge of the probe?

In the rest of my presentation I will talk about why these research questions deserve an answer and what I have done so far to answer them.

Big brother will not be mentioned anymore.

First of all I will explain briefly what is deep learning, since it gets mentioned all the time in the media. 

This is a neural network. It's a network that is composed of small units called nodes and these are connected to each other. Each connection has a weigth that indicate how important the connection is. Nodes are typically organized in layers. And when we stack these layers we get a deep neural network. Deep learning refers to this stacking of layers. 










	
	

